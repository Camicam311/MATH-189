---
title: 'CASE STUDY 4:'
output: html_notebook
---

This study allows us to revisit/renew

1. Regression modeling
2. Properties of Least Squares/Fitting "a line"
3. Multiple observation

Datasets for this study are

1. The main file: gauge.txt
2. Supplementary large-scale files: download the following folder Full Resolution Data.zip More information about the supplementary file can be found at http://iabp.apl.washington.edu/data.html as well as http://nsidc.org/data/G00791


## Question
The aim of this lab is to provide a simple procedure for converting gain into density when the gauge is in operation. Keep in mind that the experiment was conducted by varying density and measuring the response in gain, but when the gauge is ultimately in use, the snow-pack density is to be estimated from the measured gain.


## Setup
```{r}
df <- read.table('gauge-1wb1wa6-2gpel41.txt', header=TRUE)

#install.packages('L1pack')
library(L1pack)  # Used for least absolute deviations regression line
```


## Scenario 1: Fitting
Use the data to fit the gain, or a transformation of gain, to density. Try sketching the least squares line on a scatter plot.

* Do the residuals indicate any problems with the fit?
* If the densities of the polyethylene blocks are not reported exactly, how might this affect the fit?
* What if the blocks of polyethylene were not measured in random order?
```{r}
# Plot raw data
title <- 'Density vs. Gain'
x.axis <- expression('Density (g/cm'^3*')') 
y.axis <- 'Gain'
plot(df, main=title, xlab=x.axis, ylab=y.axis)


# Take log transformation of response variable (gain)
y.log.axis = 'log(Gain)'
df.log = data.frame(df['density'], log(df['gain']))
plot(df.log, main=title, xlab=x.axis, ylab=y.log.axis)


# Average replicate measurements
df.log.avg = aggregate(list(gain=df.log$gain), by=list(density=df.log$density), FUN=mean)
plot(df.log.avg, main=title, xlab=x.axis, ylab=y.log.axis)


# Fit gain to density
cor(df.log.avg)

least.squares <- lm(gain~density, data=df.log.avg)
least.absolute.deviations <- lad(gain~density, data=df.log.avg)

plot(df.log.avg, main=title, xlab=x.axis, ylab=y.log.axis)
abline(least.squares, col='red')
abline(least.absolute.deviations, col='blue')
legend('topright', legend=c('Least Squares', 'Least Absolute Deviations'), col=c('red', 'blue'), lty=1);

least.squares
summary(least.squares)
least.absolute.deviations
summary(least.absolute.deviations)


# Check conditions for linear regression: linearity, normality of residuals, constant variability
title.residuals1 <- 'Residuals of Least Squares Regression Line'
title.residuals2 <- 'Residuals of Least Absolute Deviations Regression Line'
plot(least.squares$residuals, main=title.residuals1, ylab=y.axis)
abline(0, 0, col='red')
plot(least.absolute.deviations$residuals, main=title.residuals2, ylab=y.axis)
abline(0, 0, col='blue')

num.bins <- 10
hist(least.squares$residuals, breaks=num.bins, main=title.residuals1, xlab=y.axis, col='red')
hist(least.absolute.deviations$residuals, breaks=num.bins, main=title.residuals2, xlab=y.axis, col='blue')

qqnorm(least.squares$residuals, main=paste('Normal Q-Q Plot with', title.residuals1), cex.main=1)
qqline(least.squares$residuals, col='red')
qqnorm(least.absolute.deviations$residuals, main=paste('Normal Q-Q Plot with', title.residuals2), cex.main=1)
qqline(least.absolute.deviations$residuals, col='blue')

# If the densities of the polyethylene blocks were not reported exactly, not only would we not know the density of our snow, our explanatory variable, but we could also retrieve inaccurate data for the gain from the photons. It is possible that if the density of the snow was not properly reported, our whole data set would be flawed and we could arrive at a calibration procedure different from what we would have wanted.

# Since the blocks themselves were in random locations, therefore if the measurement were not taken randomly, then it might happen that the measurements might be taken in a only specific area and thus causing bias.

# If the blocks of polyethylene were not measured in random order, there could be a dependence on the measurements of the snow densities, and our data would not be i.i.d. If we handpicked which blocks to measure or picked them in a predetermined order, the density of the snow blocks could influence how the gain was recorded for each block of snow and also produce inaccurate results.
```


## Scenario 2: Predicting
Ultimately we are interested in answering questions such as: Given a gain reading of 38.6, what is the density of the snow-pack? Given a gain reading of 426.7, what is the density of the snow-pack? These two numeric values, 38.6 and 426.7, were chosen because they are the average gains for the 0.508 and 0.001 densities, respectively.

* Develop a procedure for adding bands around your least squares line that can be used to make interval estimates for the snow-pack density from gain measurements. Keep in mind how the data were collected: several measurements of gain were taken for polyenythylene blocks of known density.

```{r}
pred.int =  predict(least.squares, interval="prediction", level=.95)
plot(pred.int)
```

```{r}
library(ggplot2)
# Least Square b0 and b1 value
b1 <-  as.numeric(coefficients((least.squares))[2])
b0 <-  as.numeric(coefficients((least.squares))[1])

# Function to use gain to predict density 
ls.regression <- function(gain){
  log.gain <-  log(gain)
  estimated.density <-  (log.gain - b0) / b1;
  return(estimated.density);
}

# Estimates for density
density.1 <- ls.regression(38.6)
density.2 <- ls.regression(426.7)

# Graph for Confidence Interval Bands for two estimates
ggplot(df.log.avg,aes(x=density, y=gain)) + 
  geom_point(color='#2980B9', size = 4) + 
  geom_smooth(method=lm, color='#2C3E50')+geom_point() +
  geom_point(aes(x=0.508, y=3.65745), colour="yellow") 

ggplot(df.log.avg,aes(x=density, y=gain)) + 
  geom_point(color='#2980B9', size = 4) + 
  geom_smooth(method=lm, color='#2C3E50')+geom_point() +
  geom_point(aes(x=0.508, y=3.65745), colour="yellow") +
  geom_point()+geom_point(aes(x=0.001, y=5.99266), colour="red")

# Parameters
delta_h <-sd(least.squares$residuals)
z <- qnorm(0.975)
m <- 9
x_bar <- mean(df$density)
den <- sum((df$density-x_bar)**2)

# Prediction Interval 
lower.pi.bound <- function(gain){
  return((-sqrt(den)*sqrt(9*x_bar*x_bar*b1*b1/z/z/delta_h/delta_h+18*x_bar*b1/z/delta_h*(b0-log(gain))/z/delta_h+10*den*b1*b1/z/delta_h/z/delta_h+9*(b0-log(gain))*(b0-log(gain))/z/z/delta_h/delta_h-10)-3*x_bar-3*den*b1*(b0-log(gain))/z/z/delta_h/delta_h)/(3*(den*(b1/z/delta_h)^2)-1))
}
upper.pi.bound <- function(gain){
  return((sqrt(den)*sqrt(9*x_bar*x_bar*b1*b1/z/z/delta_h/delta_h+18*x_bar*b1/z/delta_h*(b0-log(gain))/z/delta_h+10*den*b1*b1/z/delta_h/z/delta_h+9*(b0-log(gain))*(b0-log(gain))/z/z/delta_h/delta_h-10)-3*x_bar-3*den*b1*(b0-log(gain))/z/z/delta_h/delta_h)/(3*(den*(b1/z/delta_h)^2)-1))
}
print("The Prediction Interval for the predicted density given gain = 38.6 is")
lower.pi.bound(38.6)
upper.pi.bound(38.6)
print("The Prediction Interval for the predicted density given gain = 426.7 is")
lower.pi.bound(426.7)
upper.pi.bound(426.7)

# Parameters
t <- qt(0.975, m-2)
# Confidence Interval
lower.ci.bound <- function(gain){
  return((-sqrt(den)*sqrt(9*x_bar*x_bar*b1*b1/t/t/delta_h/delta_h+18*x_bar*b1/t/delta_h*(b0-log(gain))/t/delta_h+9*(b0-log(gain))*(b0-log(gain))/t/t/delta_h/delta_h-1)-3*x_bar-3*den*b1*(b0-log(gain))/t/t/delta_h/delta_h)/(3*(den*(b1/t/delta_h)^2)-1))
}
upper.ci.bound <- function(gain){
  return((sqrt(den)*sqrt(9*x_bar*x_bar*b1*b1/t/t/delta_h/delta_h+18*x_bar*b1/t/delta_h*(b0-log(gain))/t/delta_h+9*(b0-log(gain))*(b0-log(gain))/t/t/delta_h/delta_h-1)-3*x_bar-3*den*b1*(b0-log(gain))/t/t/delta_h/delta_h)/(3*(den*(b1/t/delta_h)^2)-1))
}
print("The Confidence Interval for the predicted density given gain = 38.6 is")
lower.ci.bound(38.6)
upper.ci.bound(38.6)
print("The Confidence Interval for the predicted density given gain = 426.7 is")
lower.ci.bound(426.7)
upper.ci.bound(426.7)

```

```{r}
# Construct Confidence Interval for density = 0.508
new.data <- data.frame(density = 0.508)
log_prediction = predict(least.squares, new.data, interval="confidence")
log_prediction
prediction <- exp(log_prediction)
prediction
# Interpretation: From the output, the fitted gain at a snow density of 0.508 (g/cm'^3*') is around 38.76. The confidence interval of (36.296, 41.3963) signifies the range in which the true population parameter lies at a 95% level of confidence.

# Construct Prediction Interval for density = 0.508
log_prediction = predict(least.squares, new.data, interval="prediction")
log_prediction
prediction <- exp(log_prediction)
prediction
# Interpretation: From the output, the fitted gain at a snow density of 0.508 (g/cm'^3*') is around 38.76. The prediction interval is (32.7544, 45.87231).

# Construct Confidence Interval for density = 0.001
new.data <- data.frame(density = 0.001)
log_prediction = predict(least.squares, new.data, interval="confidence")
log_prediction
prediction <- exp(log_prediction)
prediction
# Interpretation: From the output, the fitted gain at a snow density of 0.508 (g/cm'^3*') is around 400.4783. The confidence interval of (365.3647, 438.9665) signifies the range in which the true population parameter lies at a 95% level of confidence.

# Construct Prediction Interval for density = 0.001
log_prediction = predict(least.squares, new.data, interval="prediction")
log_prediction
prediction <- exp(log_prediction)
prediction
# Interpretation: From the output, the fitted gain at a snow density of 0.508 (g/cm'^3*') is around 400.4783. The prediction interval is (334.4508, 479.541).

```


## Scenario 3: Cross-Validation
To check how well your procedure works, omit the set of measurements corresponding to the block of density 0.508, apply your "estimation"/calibration procedure to the remaining data, and provide an interval estimate for the density of a block with an average reading of 38.6. Where does the actual density fall in the interval? Try the same test, for the set of measurements at the 0.001 density.
```{r}

```


## Additional Scenario: TODO Title
Use the additional dataset to construct a model fitting temperature with DOY, latitude, and other reasonable features. Try sketching the least squares line on a scatter plot. We aim to investigate the relationship between temperature and the DOY, and its Latitude.
```{r}
# Check the correlation
data <- read.csv('Full Resolution Data/64506420.csv', header=TRUE)
data <- data[,c('Hour','DOY','POS_DOY','Lat','Lon','Ts','BP')]

# Drop the extreme outlier case
#data <- data[which(data$Ts>-200),]
data_matrix <- as.matrix(data)

# Correlation Matrix
corr_matrix <- cor(data_matrix)
corr_matrix
```
```{r}
# least squares line
fit<-lm(formula = Ts ~ DOY + Lat, data = data)
summary(fit)

ggplot(data,aes(x=DOY, y=Ts)) + 
  geom_point(color='#2980B9', size = 4) + 
  geom_smooth(method=lm, color='#2C3E50')

ggplot(data,aes(x=Lat, y=Ts)) + 
  geom_point(color='#2980B9', size = 4) + 
  geom_smooth(method=lm, color='#2C3E50')

title.residuals1 <- 'Residuals of Least Squares Regression Line'
plot(fit$residuals, main=title.residuals1)
abline(0, 0, col='red')

num.bins <- 10
hist(fit$residuals, breaks=num.bins, main=title.residuals1, xlab='Temperature', col='red')

qqnorm(fit$residuals, main=paste('Normal Q-Q Plot with', title.residuals1), cex.main=1)
qqline(fit$residuals, col='red')
```

```{r}
# Attempt for Multiple Regressions
data$Midnights <- 0
data$Midnights[which(data$Hour<6)] <- 1
data$Mornings <- 0
data$Mornings[which(data$Hour>=6 & data$Hour<11)] <- 1 
data$Noon <- 0
data$Noon[which(data$Hour>=11 & data$Hour<15)] <- 1
data$Afternoon <- 0
data$Afternoon[which(data$Hour>=15 & data$Hour<20)] <- 1
data$Nights <- 0
data$Nights[which(data$Hour>=20)] <- 1
```